{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "221ce57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from typing import Any\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score   \n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import warnings\n",
    "warnings.filterwarnings('always')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe2e2d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b9fcafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  RoadImageReader import RoadImageReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca4f98e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GaborNN import GaborNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43873d63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fa99f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "504d02c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = RoadImageReader(\n",
    "        root_dir=os.path.join(\"C:\\\\Users\\\\91701\\\\OneDrive\\\\thesiscode\\\\data\", \"train\"), transform=transform\n",
    "    )\n",
    "test_set = RoadImageReader(\n",
    "        root_dir=os.path.join(\"C:\\\\Users\\\\91701\\\\OneDrive\\\\thesiscode\\\\data\", \"test\"), transform=transform\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1160cd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=7)\n",
    "test = DataLoader(test_set, batch_size=128, shuffle=True, num_workers=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d626292b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d013925e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "net = GaborNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(net.parameters())\n",
    "#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.01, max_lr=0.1,cycle_momentum=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2888ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4764ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d74fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_layer_gnet_acc_train = []\n",
    "one_layer_gnet_acc_test = []\n",
    "time_per_image_train = []\n",
    "time_per_image_test = []\n",
    "\n",
    "data_dict = {'MODEL':[],\n",
    "        'EPOCH':[],\n",
    "        'TRAINACC':[],\n",
    "        'TRAINLOSS':[],\n",
    "        'TESTACC':[],\n",
    "        'TESTLOSS':[],\n",
    "        'TIME':[],\n",
    "        'TRAINPRECISION':[],\n",
    "        'TRAINRECALL':[],\n",
    "        'TRAINF1SCORE':[],\n",
    "        'TESTPRECISION':[],\n",
    "        'TESTRECALL':[],\n",
    "        'TESTF1SCORE':[],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d7dbd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setDataDict(model,epoch,trainacc,trainloss,testacc,testloss,time,trpre,trre,trf1,tepre,tere,tef1):\n",
    "    data_dict['MODEL'].append(model)\n",
    "    data_dict['EPOCH'].append(epoch)\n",
    "    data_dict['TRAINACC'].append(trainacc)\n",
    "    data_dict['TRAINLOSS'].append(trainloss)\n",
    "    data_dict['TESTACC'].append(testacc)\n",
    "    data_dict['TESTLOSS'].append(testloss)\n",
    "    data_dict['TIME'].append(time)\n",
    "    data_dict['TRAINPRECISION'].append(trpre)\n",
    "    data_dict['TRAINRECALL'].append(trre)\n",
    "    data_dict['TRAINF1SCORE'].append(trf1)\n",
    "    data_dict['TESTPRECISION'].append(tepre)\n",
    "    data_dict['TESTRECALL'].append(tere)\n",
    "    data_dict['TESTF1SCORE'].append(tef1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08cea3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingData(net,criterion,optimizer,epochs,modelName):\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        epochTime=time.perf_counter()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        trainrecall=[]\n",
    "        trainprecision=[]\n",
    "        testrecall=[]\n",
    "        testprecision=[]\n",
    "        label=[]\n",
    "        net.train()\n",
    "        start = time.perf_counter()\n",
    "        for data in train:\n",
    "            # get the inputs\n",
    "            inputs, labels = data[\"image\"], data[\"target\"]\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs.to(device))\n",
    "            loss = criterion(outputs, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #scheduler.step()\n",
    "            pred = outputs.max(1, keepdim=True)[1].to(\"cpu\")\n",
    "\n",
    "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "            trainprecision.append(precision_score(labels.data, pred))\n",
    "            trainrecall.append(recall_score(labels.data, pred))\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "        finish = time.perf_counter()\n",
    "\n",
    "        trainPrecisionScore=sum(trainprecision)/len(trainprecision)\n",
    "        trainRecallScore=sum(trainrecall)/len(trainrecall)\n",
    "        trainF1score=(2*(trainPrecisionScore*trainRecallScore))/(trainPrecisionScore+trainRecallScore)\n",
    "\n",
    "        time_per_image_train.append((finish - start) / len(train_set))\n",
    "        print(\n",
    "            \"[%d] train_acc: %.3f train_loss: %.3f\"\n",
    "            % (epoch + 1, correct / len(train_set), running_loss / len(train_set))\n",
    "        )\n",
    "        one_layer_gnet_acc_train.append(correct / len(train_set))\n",
    "        train_loss=running_loss / len(train_set)\n",
    "        train_acc=correct / len(train_set)\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        start = time.perf_counter()\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            for data in test:\n",
    "                # get the inputs\n",
    "                inputs, labels = data[\"image\"], data[\"target\"]\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = net(inputs.to(device))\n",
    "                loss = criterion(outputs, labels.to(device))\n",
    "\n",
    "                pred = outputs.max(1, keepdim=True)[1].to(\"cpu\")\n",
    "                correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "                testprecision.append(precision_score(labels.data, pred))\n",
    "                testrecall.append(recall_score(labels.data, pred))\n",
    "                running_loss += loss.item()\n",
    "        finish = time.perf_counter()\n",
    "        testPrecisionScore=sum(testprecision)/len(testprecision)\n",
    "        testRecallScore=sum(testrecall)/len(testrecall)\n",
    "        testF1score=(2*(testPrecisionScore*testRecallScore))/(testPrecisionScore+testRecallScore)\n",
    "        time_per_image_test.append((finish - start) / len(test_set))\n",
    "        print(\n",
    "            \"[%d] test_acc: %.3f test_loss: %.3f\"\n",
    "            % (epoch + 1, correct / len(test_set), running_loss / len(test_set))\n",
    "        )\n",
    "        one_layer_gnet_acc_test.append(correct / len(test_set))\n",
    "        epochTime=time.perf_counter()-epochTime\n",
    "        setDataDict(modelName,epoch+1,train_acc,train_loss,correct / len(test_set), running_loss / len(test_set),epochTime,trainPrecisionScore,trainRecallScore,trainF1score,testPrecisionScore,testRecallScore,testF1score)\n",
    "        torch.save(net, modelName+\"\\\\\"+modelName+str(epoch+1)+\".pt\")\n",
    "        print(\"Time Taken in Epoch \"+ str(epoch+1)+\"  Seconds: \"+str(epochTime))\n",
    "\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573c763f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcee423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f0f16d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71c11a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622f380b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7442dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GaborNNWithResnet import GaborNNWithResnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99d63179",
   "metadata": {},
   "outputs": [],
   "source": [
    "net =GaborNNWithResnet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd27b2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_layer_gnet_acc_train = []\n",
    "one_layer_gnet_acc_test = []\n",
    "time_per_image_train = []\n",
    "time_per_image_test = []\n",
    "epochs=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "297cb460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] train_acc: 0.632 train_loss: 0.005\n",
      "[1] test_acc: 0.709 test_loss: 0.005\n",
      "Time Taken in Epoch 1  Seconds: 8441.6435396\n",
      "[2] train_acc: 0.664 train_loss: 0.005\n",
      "[2] test_acc: 0.720 test_loss: 0.004\n",
      "Time Taken in Epoch 2  Seconds: 9804.0646562\n",
      "[3] train_acc: 0.671 train_loss: 0.005\n",
      "[3] test_acc: 0.679 test_loss: 0.005\n",
      "Time Taken in Epoch 3  Seconds: 9766.8223311\n",
      "[4] train_acc: 0.676 train_loss: 0.005\n",
      "[4] test_acc: 0.722 test_loss: 0.004\n",
      "Time Taken in Epoch 4  Seconds: 9851.556368499998\n",
      "[5] train_acc: 0.675 train_loss: 0.005\n",
      "[5] test_acc: 0.718 test_loss: 0.004\n",
      "Time Taken in Epoch 5  Seconds: 9540.671708299997\n",
      "[6] train_acc: 0.682 train_loss: 0.005\n",
      "[6] test_acc: 0.698 test_loss: 0.005\n",
      "Time Taken in Epoch 6  Seconds: 9423.9133669\n",
      "[7] train_acc: 0.685 train_loss: 0.005\n",
      "[7] test_acc: 0.723 test_loss: 0.004\n",
      "Time Taken in Epoch 7  Seconds: 9173.414561599995\n",
      "[8] train_acc: 0.691 train_loss: 0.005\n",
      "[8] test_acc: 0.709 test_loss: 0.004\n",
      "Time Taken in Epoch 8  Seconds: 9122.038816100001\n",
      "[9] train_acc: 0.686 train_loss: 0.005\n",
      "[9] test_acc: 0.705 test_loss: 0.005\n",
      "Time Taken in Epoch 9  Seconds: 8842.840034199995\n",
      "[10] train_acc: 0.688 train_loss: 0.005\n",
      "[10] test_acc: 0.722 test_loss: 0.004\n",
      "Time Taken in Epoch 10  Seconds: 9373.4754063\n",
      "[11] train_acc: 0.690 train_loss: 0.005\n",
      "[11] test_acc: 0.722 test_loss: 0.004\n",
      "Time Taken in Epoch 11  Seconds: 10002.7344094\n",
      "[12] train_acc: 0.693 train_loss: 0.005\n",
      "[12] test_acc: 0.725 test_loss: 0.004\n",
      "Time Taken in Epoch 12  Seconds: 9400.0248001\n",
      "[13] train_acc: 0.692 train_loss: 0.005\n",
      "[13] test_acc: 0.717 test_loss: 0.004\n",
      "Time Taken in Epoch 13  Seconds: 9967.361650299994\n",
      "[14] train_acc: 0.694 train_loss: 0.005\n",
      "[14] test_acc: 0.710 test_loss: 0.005\n",
      "Time Taken in Epoch 14  Seconds: 9484.31646619999\n",
      "[15] train_acc: 0.695 train_loss: 0.004\n",
      "[15] test_acc: 0.720 test_loss: 0.004\n",
      "Time Taken in Epoch 15  Seconds: 9464.400536700006\n",
      "[16] train_acc: 0.693 train_loss: 0.005\n",
      "[16] test_acc: 0.719 test_loss: 0.004\n",
      "Time Taken in Epoch 16  Seconds: 9307.4662007\n",
      "[17] train_acc: 0.694 train_loss: 0.004\n",
      "[17] test_acc: 0.683 test_loss: 0.005\n",
      "Time Taken in Epoch 17  Seconds: 9398.608968199987\n",
      "[18] train_acc: 0.691 train_loss: 0.005\n",
      "[18] test_acc: 0.711 test_loss: 0.005\n",
      "Time Taken in Epoch 18  Seconds: 9231.186567199999\n",
      "[19] train_acc: 0.692 train_loss: 0.005\n",
      "[19] test_acc: 0.727 test_loss: 0.004\n",
      "Time Taken in Epoch 19  Seconds: 9338.788446999999\n",
      "[20] train_acc: 0.687 train_loss: 0.004\n",
      "[20] test_acc: 0.724 test_loss: 0.004\n",
      "Time Taken in Epoch 20  Seconds: 10124.80262859998\n",
      "[21] train_acc: 0.691 train_loss: 0.005\n",
      "[21] test_acc: 0.729 test_loss: 0.004\n",
      "Time Taken in Epoch 21  Seconds: 9735.943127300008\n",
      "[22] train_acc: 0.692 train_loss: 0.004\n",
      "[22] test_acc: 0.727 test_loss: 0.004\n",
      "Time Taken in Epoch 22  Seconds: 9984.846531899995\n",
      "[23] train_acc: 0.693 train_loss: 0.004\n",
      "[23] test_acc: 0.720 test_loss: 0.004\n",
      "Time Taken in Epoch 23  Seconds: 9527.123917799996\n",
      "[24] train_acc: 0.692 train_loss: 0.004\n",
      "[24] test_acc: 0.719 test_loss: 0.004\n",
      "Time Taken in Epoch 24  Seconds: 9389.22568599999\n",
      "[25] train_acc: 0.694 train_loss: 0.004\n",
      "[25] test_acc: 0.711 test_loss: 0.005\n",
      "Time Taken in Epoch 25  Seconds: 9255.001829099987\n",
      "[26] train_acc: 0.695 train_loss: 0.004\n",
      "[26] test_acc: 0.720 test_loss: 0.004\n",
      "Time Taken in Epoch 26  Seconds: 9377.313339299988\n",
      "[27] train_acc: 0.696 train_loss: 0.004\n",
      "[27] test_acc: 0.714 test_loss: 0.004\n",
      "Time Taken in Epoch 27  Seconds: 23296.75021680002\n",
      "[28] train_acc: 0.695 train_loss: 0.005\n",
      "[28] test_acc: 0.722 test_loss: 0.004\n",
      "Time Taken in Epoch 28  Seconds: 9555.802807299944\n",
      "[29] train_acc: 0.693 train_loss: 0.004\n",
      "[29] test_acc: 0.727 test_loss: 0.004\n",
      "Time Taken in Epoch 29  Seconds: 9712.439930199995\n",
      "[30] train_acc: 0.695 train_loss: 0.004\n",
      "[30] test_acc: 0.727 test_loss: 0.004\n",
      "Time Taken in Epoch 30  Seconds: 9710.465064699994\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "trainingData(net,criterion,optimizer,epochs,'RESNET18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe1befe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, \"RESNET18.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe28e4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"result.csv\");\n",
    "\n",
    "df=pd.concat([df,pd.DataFrame(data_dict)],ignore_index = True)\n",
    "df.to_csv(\"result.csv\", index=False)\n",
    "data_dict = {'MODEL':[],\n",
    "        'EPOCH':[],\n",
    "        'TRAINACC':[],\n",
    "        'TRAINLOSS':[],\n",
    "        'TESTACC':[],\n",
    "        'TESTLOSS':[],\n",
    "        'TIME':[],\n",
    "        'TRAINPRECISION':[],\n",
    "        'TRAINRECALL':[],\n",
    "        'TRAINF1SCORE':[],\n",
    "        'TESTPRECISION':[],\n",
    "        'TESTRECALL':[],\n",
    "        'TESTF1SCORE':[],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f67fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8869e10a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9c2452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
