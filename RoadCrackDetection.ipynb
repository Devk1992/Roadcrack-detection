{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "221ce57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from typing import Any\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score   \n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import warnings\n",
    "warnings.filterwarnings('always')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe2e2d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b9fcafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  RoadImageReader import RoadImageReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca4f98e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GaborNN import GaborNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43873d63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fa99f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "504d02c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = RoadImageReader(\n",
    "        root_dir=os.path.join(\"C:\\\\Users\\\\91701\\\\OneDrive\\\\thesiscode\\\\data\", \"train\"), transform=transform\n",
    "    )\n",
    "test_set = RoadImageReader(\n",
    "        root_dir=os.path.join(\"C:\\\\Users\\\\91701\\\\OneDrive\\\\thesiscode\\\\data\", \"test\"), transform=transform\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1160cd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=7)\n",
    "test = DataLoader(test_set, batch_size=128, shuffle=True, num_workers=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d626292b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d013925e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "net = GaborNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(net.parameters())\n",
    "#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.01, max_lr=0.1,cycle_momentum=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2888ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4764ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d74fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_layer_gnet_acc_train = []\n",
    "one_layer_gnet_acc_test = []\n",
    "time_per_image_train = []\n",
    "time_per_image_test = []\n",
    "\n",
    "data_dict = {'MODEL':[],\n",
    "        'EPOCH':[],\n",
    "        'TRAINACC':[],\n",
    "        'TRAINLOSS':[],\n",
    "        'TESTACC':[],\n",
    "        'TESTLOSS':[],\n",
    "        'TIME':[],\n",
    "        'TRAINPRECISION':[],\n",
    "        'TRAINRECALL':[],\n",
    "        'TRAINF1SCORE':[],\n",
    "        'TESTPRECISION':[],\n",
    "        'TESTRECALL':[],\n",
    "        'TESTF1SCORE':[],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d7dbd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setDataDict(model,epoch,trainacc,trainloss,testacc,testloss,time,trpre,trre,trf1,tepre,tere,tef1):\n",
    "    data_dict['MODEL'].append(model)\n",
    "    data_dict['EPOCH'].append(epoch)\n",
    "    data_dict['TRAINACC'].append(trainacc)\n",
    "    data_dict['TRAINLOSS'].append(trainloss)\n",
    "    data_dict['TESTACC'].append(testacc)\n",
    "    data_dict['TESTLOSS'].append(testloss)\n",
    "    data_dict['TIME'].append(time)\n",
    "    data_dict['TRAINPRECISION'].append(trpre)\n",
    "    data_dict['TRAINRECALL'].append(trre)\n",
    "    data_dict['TRAINF1SCORE'].append(trf1)\n",
    "    data_dict['TESTPRECISION'].append(tepre)\n",
    "    data_dict['TESTRECALL'].append(tere)\n",
    "    data_dict['TESTF1SCORE'].append(tef1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08cea3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingData(net,criterion,optimizer,epochs,modelName):\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        epochTime=time.perf_counter()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        trainrecall=[]\n",
    "        trainprecision=[]\n",
    "        testrecall=[]\n",
    "        testprecision=[]\n",
    "        label=[]\n",
    "        net.train()\n",
    "        start = time.perf_counter()\n",
    "        for data in train:\n",
    "            # get the inputs\n",
    "            inputs, labels = data[\"image\"], data[\"target\"]\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs.to(device))\n",
    "            loss = criterion(outputs, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #scheduler.step()\n",
    "            pred = outputs.max(1, keepdim=True)[1].to(\"cpu\")\n",
    "\n",
    "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "            trainprecision.append(precision_score(labels.data, pred))\n",
    "            trainrecall.append(recall_score(labels.data, pred))\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "        finish = time.perf_counter()\n",
    "\n",
    "        trainPrecisionScore=sum(trainprecision)/len(trainprecision)\n",
    "        trainRecallScore=sum(trainrecall)/len(trainrecall)\n",
    "        trainF1score=(2*(trainPrecisionScore*trainRecallScore))/(trainPrecisionScore+trainRecallScore)\n",
    "\n",
    "        time_per_image_train.append((finish - start) / len(train_set))\n",
    "        print(\n",
    "            \"[%d] train_acc: %.3f train_loss: %.3f\"\n",
    "            % (epoch + 1, correct / len(train_set), running_loss / len(train_set))\n",
    "        )\n",
    "        one_layer_gnet_acc_train.append(correct / len(train_set))\n",
    "        train_loss=running_loss / len(train_set)\n",
    "        train_acc=correct / len(train_set)\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        start = time.perf_counter()\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            for data in test:\n",
    "                # get the inputs\n",
    "                inputs, labels = data[\"image\"], data[\"target\"]\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = net(inputs.to(device))\n",
    "                loss = criterion(outputs, labels.to(device))\n",
    "\n",
    "                pred = outputs.max(1, keepdim=True)[1].to(\"cpu\")\n",
    "                correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "                testprecision.append(precision_score(labels.data, pred))\n",
    "                testrecall.append(recall_score(labels.data, pred))\n",
    "                running_loss += loss.item()\n",
    "        finish = time.perf_counter()\n",
    "        testPrecisionScore=sum(testprecision)/len(testprecision)\n",
    "        testRecallScore=sum(testrecall)/len(testrecall)\n",
    "        testF1score=(2*(testPrecisionScore*testRecallScore))/(testPrecisionScore+testRecallScore)\n",
    "        time_per_image_test.append((finish - start) / len(test_set))\n",
    "        print(\n",
    "            \"[%d] test_acc: %.3f test_loss: %.3f\"\n",
    "            % (epoch + 1, correct / len(test_set), running_loss / len(test_set))\n",
    "        )\n",
    "        one_layer_gnet_acc_test.append(correct / len(test_set))\n",
    "        epochTime=time.perf_counter()-epochTime\n",
    "        setDataDict(modelName,epoch+1,train_acc,train_loss,correct / len(test_set), running_loss / len(test_set),epochTime,trainPrecisionScore,trainRecallScore,trainF1score,testPrecisionScore,testRecallScore,testF1score)\n",
    "        torch.save(net, modelName+\"\\\\\"+modelName+str(epoch+1)+\".pt\")\n",
    "        print(\"Time Taken in Epoch \"+ str(epoch+1)+\"  Seconds: \"+str(epochTime))\n",
    "\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9a46157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] train_acc: 0.505 train_loss: 0.005\n",
      "[1] test_acc: 0.518 test_loss: 0.006\n",
      "Time Taken in Epoch 1  Seconds: 1164.4910563\n",
      "[2] train_acc: 0.538 train_loss: 0.005\n",
      "[2] test_acc: 0.573 test_loss: 0.005\n",
      "Time Taken in Epoch 2  Seconds: 1095.4786877000001\n",
      "[3] train_acc: 0.563 train_loss: 0.005\n",
      "[3] test_acc: 0.620 test_loss: 0.005\n",
      "Time Taken in Epoch 3  Seconds: 1113.4954306\n",
      "[4] train_acc: 0.592 train_loss: 0.005\n",
      "[4] test_acc: 0.607 test_loss: 0.005\n",
      "Time Taken in Epoch 4  Seconds: 1120.4467411000005\n",
      "[5] train_acc: 0.619 train_loss: 0.005\n",
      "[5] test_acc: 0.650 test_loss: 0.005\n",
      "Time Taken in Epoch 5  Seconds: 1113.6744872\n",
      "[6] train_acc: 0.630 train_loss: 0.005\n",
      "[6] test_acc: 0.684 test_loss: 0.005\n",
      "Time Taken in Epoch 6  Seconds: 1113.8237159\n",
      "[7] train_acc: 0.645 train_loss: 0.005\n",
      "[7] test_acc: 0.700 test_loss: 0.005\n",
      "Time Taken in Epoch 7  Seconds: 1121.4635444999994\n",
      "[8] train_acc: 0.662 train_loss: 0.005\n",
      "[8] test_acc: 0.704 test_loss: 0.005\n",
      "Time Taken in Epoch 8  Seconds: 1095.1785481999996\n",
      "[9] train_acc: 0.666 train_loss: 0.005\n",
      "[9] test_acc: 0.696 test_loss: 0.005\n",
      "Time Taken in Epoch 9  Seconds: 1106.3743433\n",
      "[10] train_acc: 0.676 train_loss: 0.005\n",
      "[10] test_acc: 0.713 test_loss: 0.004\n",
      "Time Taken in Epoch 10  Seconds: 1110.7888824000001\n",
      "[11] train_acc: 0.682 train_loss: 0.005\n",
      "[11] test_acc: 0.713 test_loss: 0.004\n",
      "Time Taken in Epoch 11  Seconds: 1098.4816128000002\n",
      "[12] train_acc: 0.685 train_loss: 0.004\n",
      "[12] test_acc: 0.719 test_loss: 0.004\n",
      "Time Taken in Epoch 12  Seconds: 1102.8167804000004\n",
      "[13] train_acc: 0.692 train_loss: 0.004\n",
      "[13] test_acc: 0.725 test_loss: 0.004\n",
      "Time Taken in Epoch 13  Seconds: 1105.8877335000016\n",
      "[14] train_acc: 0.701 train_loss: 0.004\n",
      "[14] test_acc: 0.724 test_loss: 0.004\n",
      "Time Taken in Epoch 14  Seconds: 1102.7980817000007\n",
      "[15] train_acc: 0.709 train_loss: 0.004\n",
      "[15] test_acc: 0.726 test_loss: 0.004\n",
      "Time Taken in Epoch 15  Seconds: 1105.2277908999986\n",
      "[16] train_acc: 0.714 train_loss: 0.004\n",
      "[16] test_acc: 0.723 test_loss: 0.004\n",
      "Time Taken in Epoch 16  Seconds: 1103.8182056000005\n",
      "[17] train_acc: 0.716 train_loss: 0.004\n",
      "[17] test_acc: 0.732 test_loss: 0.004\n",
      "Time Taken in Epoch 17  Seconds: 1100.0684540000002\n",
      "[18] train_acc: 0.721 train_loss: 0.004\n",
      "[18] test_acc: 0.735 test_loss: 0.004\n",
      "Time Taken in Epoch 18  Seconds: 1105.9387709000002\n",
      "[19] train_acc: 0.721 train_loss: 0.004\n",
      "[19] test_acc: 0.744 test_loss: 0.004\n",
      "Time Taken in Epoch 19  Seconds: 1113.6315379999978\n",
      "[20] train_acc: 0.733 train_loss: 0.004\n",
      "[20] test_acc: 0.739 test_loss: 0.004\n",
      "Time Taken in Epoch 20  Seconds: 1111.2376694999984\n",
      "[21] train_acc: 0.733 train_loss: 0.004\n",
      "[21] test_acc: 0.731 test_loss: 0.004\n",
      "Time Taken in Epoch 21  Seconds: 1101.2086816999981\n",
      "[22] train_acc: 0.735 train_loss: 0.004\n",
      "[22] test_acc: 0.732 test_loss: 0.004\n",
      "Time Taken in Epoch 22  Seconds: 1099.243991200001\n",
      "[23] train_acc: 0.741 train_loss: 0.004\n",
      "[23] test_acc: 0.738 test_loss: 0.004\n",
      "Time Taken in Epoch 23  Seconds: 1107.6604066\n",
      "[24] train_acc: 0.748 train_loss: 0.004\n",
      "[24] test_acc: 0.732 test_loss: 0.004\n",
      "Time Taken in Epoch 24  Seconds: 1106.3278941999997\n",
      "[25] train_acc: 0.750 train_loss: 0.004\n",
      "[25] test_acc: 0.739 test_loss: 0.004\n",
      "Time Taken in Epoch 25  Seconds: 1096.7687783000001\n",
      "[26] train_acc: 0.758 train_loss: 0.004\n",
      "[26] test_acc: 0.733 test_loss: 0.004\n",
      "Time Taken in Epoch 26  Seconds: 1102.1866415000004\n",
      "[27] train_acc: 0.763 train_loss: 0.004\n",
      "[27] test_acc: 0.733 test_loss: 0.005\n",
      "Time Taken in Epoch 27  Seconds: 1104.0470870999998\n",
      "[28] train_acc: 0.764 train_loss: 0.004\n",
      "[28] test_acc: 0.727 test_loss: 0.004\n",
      "Time Taken in Epoch 28  Seconds: 1107.813323399998\n",
      "[29] train_acc: 0.770 train_loss: 0.004\n",
      "[29] test_acc: 0.739 test_loss: 0.004\n",
      "Time Taken in Epoch 29  Seconds: 1096.0273783999983\n",
      "[30] train_acc: 0.771 train_loss: 0.004\n",
      "[30] test_acc: 0.731 test_loss: 0.005\n",
      "Time Taken in Epoch 30  Seconds: 1089.3833339999983\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "trainingData(net,criterion,optimizer,epochs,'GABORNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8edc14ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"result.csv\");\n",
    "\n",
    "df=pd.concat([df,pd.DataFrame(data_dict)],ignore_index = True)\n",
    "df.to_csv(\"result.csv\", index=False)\n",
    "data_dict = {'MODEL':[],\n",
    "        'EPOCH':[],\n",
    "        'TRAINACC':[],\n",
    "        'TRAINLOSS':[],\n",
    "        'TESTACC':[],\n",
    "        'TESTLOSS':[],\n",
    "        'TIME':[],\n",
    "        'TRAINPRECISION':[],\n",
    "        'TRAINRECALL':[],\n",
    "        'TRAINF1SCORE':[],\n",
    "        'TESTPRECISION':[],\n",
    "        'TESTRECALL':[],\n",
    "        'TESTF1SCORE':[],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2ee0975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(net.state_dict(), \"gabornn.pt\")\n",
    "torch.save(net, \"GABORNN.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9e0e9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaborNN(\n",
       "  (g1): GaborConv2dLayer(\n",
       "    (conv_layer): Conv2d(3, 32, kernel_size=(15, 15), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (c1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (c2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (fc1): Linear(in_features=6272, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('GABORNN.pt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ee57a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {\n",
    "    \"train_acc\": one_layer_gnet_acc_train[-1],\n",
    "    \"test_acc\": one_layer_gnet_acc_test[-1],\n",
    "    \"time_per_image_train\": sum(time_per_image_train) / len(time_per_image_train),\n",
    "    \"time_per_image_test\": sum(time_per_image_test) / len(time_per_image_test),\n",
    "}\n",
    "with open(\"../metrics.json\", \"w+\") as outfile:\n",
    "    json.dump(result_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c36a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed77b96c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9114d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9993cb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3ad2e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ModelNN import SimpleNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df709b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SimpleNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(net.parameters())\n",
    "#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.01, max_lr=0.1,cycle_momentum=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36810777",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_layer_gnet_acc_train = []\n",
    "one_layer_gnet_acc_test = []\n",
    "time_per_image_train = []\n",
    "time_per_image_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7346642",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] train_acc: 0.528 train_loss: 0.005\n",
      "[1] test_acc: 0.539 test_loss: 0.006\n",
      "Time Taken in Epoch 1  Seconds: 1103.0474020000038\n",
      "[2] train_acc: 0.558 train_loss: 0.005\n",
      "[2] test_acc: 0.567 test_loss: 0.005\n",
      "Time Taken in Epoch 2  Seconds: 1094.7783917999986\n",
      "[3] train_acc: 0.575 train_loss: 0.005\n",
      "[3] test_acc: 0.596 test_loss: 0.005\n",
      "Time Taken in Epoch 3  Seconds: 1096.1629306000032\n",
      "[4] train_acc: 0.591 train_loss: 0.005\n",
      "[4] test_acc: 0.611 test_loss: 0.005\n",
      "Time Taken in Epoch 4  Seconds: 1089.8836798000048\n",
      "[5] train_acc: 0.593 train_loss: 0.005\n",
      "[5] test_acc: 0.603 test_loss: 0.005\n",
      "Time Taken in Epoch 5  Seconds: 1087.9936659000014\n",
      "[6] train_acc: 0.593 train_loss: 0.005\n",
      "[6] test_acc: 0.618 test_loss: 0.005\n",
      "Time Taken in Epoch 6  Seconds: 1080.6562752999962\n",
      "[7] train_acc: 0.611 train_loss: 0.005\n",
      "[7] test_acc: 0.630 test_loss: 0.005\n",
      "Time Taken in Epoch 7  Seconds: 1080.0842963999967\n",
      "[8] train_acc: 0.623 train_loss: 0.005\n",
      "[8] test_acc: 0.643 test_loss: 0.005\n",
      "Time Taken in Epoch 8  Seconds: 1082.4122916999986\n",
      "[9] train_acc: 0.629 train_loss: 0.005\n",
      "[9] test_acc: 0.650 test_loss: 0.005\n",
      "Time Taken in Epoch 9  Seconds: 1102.4747932000028\n",
      "[10] train_acc: 0.632 train_loss: 0.005\n",
      "[10] test_acc: 0.658 test_loss: 0.005\n",
      "Time Taken in Epoch 10  Seconds: 1085.2189851000003\n",
      "[11] train_acc: 0.646 train_loss: 0.005\n",
      "[11] test_acc: 0.659 test_loss: 0.005\n",
      "Time Taken in Epoch 11  Seconds: 1084.6207178999975\n",
      "[12] train_acc: 0.650 train_loss: 0.005\n",
      "[12] test_acc: 0.679 test_loss: 0.005\n",
      "Time Taken in Epoch 12  Seconds: 1098.8701327000017\n",
      "[13] train_acc: 0.662 train_loss: 0.005\n",
      "[13] test_acc: 0.692 test_loss: 0.005\n",
      "Time Taken in Epoch 13  Seconds: 1107.1872551999986\n",
      "[14] train_acc: 0.662 train_loss: 0.005\n",
      "[14] test_acc: 0.691 test_loss: 0.005\n",
      "Time Taken in Epoch 14  Seconds: 1096.315756600001\n",
      "[15] train_acc: 0.674 train_loss: 0.005\n",
      "[15] test_acc: 0.702 test_loss: 0.005\n",
      "Time Taken in Epoch 15  Seconds: 1098.4452196999991\n",
      "[16] train_acc: 0.675 train_loss: 0.005\n",
      "[16] test_acc: 0.677 test_loss: 0.005\n",
      "Time Taken in Epoch 16  Seconds: 1100.1360935999983\n",
      "[17] train_acc: 0.684 train_loss: 0.005\n",
      "[17] test_acc: 0.695 test_loss: 0.005\n",
      "Time Taken in Epoch 17  Seconds: 1093.1716425999984\n",
      "[18] train_acc: 0.678 train_loss: 0.005\n",
      "[18] test_acc: 0.698 test_loss: 0.005\n",
      "Time Taken in Epoch 18  Seconds: 1073.6175497000004\n",
      "[19] train_acc: 0.688 train_loss: 0.004\n",
      "[19] test_acc: 0.680 test_loss: 0.005\n",
      "Time Taken in Epoch 19  Seconds: 1077.620590300001\n",
      "[20] train_acc: 0.696 train_loss: 0.004\n",
      "[20] test_acc: 0.708 test_loss: 0.005\n",
      "Time Taken in Epoch 20  Seconds: 1103.3414601999975\n",
      "[21] train_acc: 0.695 train_loss: 0.004\n",
      "[21] test_acc: 0.702 test_loss: 0.005\n",
      "Time Taken in Epoch 21  Seconds: 1954.7950076999987\n",
      "[22] train_acc: 0.700 train_loss: 0.004\n",
      "[22] test_acc: 0.660 test_loss: 0.005\n",
      "Time Taken in Epoch 22  Seconds: 1125.4205193000016\n",
      "[23] train_acc: 0.708 train_loss: 0.004\n",
      "[23] test_acc: 0.701 test_loss: 0.005\n",
      "Time Taken in Epoch 23  Seconds: 1107.5743249000006\n",
      "[24] train_acc: 0.713 train_loss: 0.004\n",
      "[24] test_acc: 0.708 test_loss: 0.005\n",
      "Time Taken in Epoch 24  Seconds: 1116.5008879000015\n",
      "[25] train_acc: 0.720 train_loss: 0.004\n",
      "[25] test_acc: 0.703 test_loss: 0.005\n",
      "Time Taken in Epoch 25  Seconds: 1113.2243486000007\n",
      "[26] train_acc: 0.719 train_loss: 0.004\n",
      "[26] test_acc: 0.717 test_loss: 0.005\n",
      "Time Taken in Epoch 26  Seconds: 1112.4645812000017\n",
      "[27] train_acc: 0.727 train_loss: 0.004\n",
      "[27] test_acc: 0.714 test_loss: 0.005\n",
      "Time Taken in Epoch 27  Seconds: 1108.6770703000002\n",
      "[28] train_acc: 0.731 train_loss: 0.004\n",
      "[28] test_acc: 0.714 test_loss: 0.005\n",
      "Time Taken in Epoch 28  Seconds: 1112.1434976999954\n",
      "[29] train_acc: 0.738 train_loss: 0.004\n",
      "[29] test_acc: 0.704 test_loss: 0.005\n",
      "Time Taken in Epoch 29  Seconds: 1106.1010363999958\n",
      "[30] train_acc: 0.745 train_loss: 0.004\n",
      "[30] test_acc: 0.717 test_loss: 0.005\n",
      "Time Taken in Epoch 30  Seconds: 1104.9523889999982\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "trainingData(net,criterion,optimizer,epochs,'SimpleNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "295e5a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(net, \"SimpleNN.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c78bc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNN(\n",
       "  (c1): Conv2d(3, 32, kernel_size=(15, 15), stride=(1, 1))\n",
       "  (c2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (c3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (fc1): Linear(in_features=6272, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('SimpleNN.pt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29536820",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"result.csv\");\n",
    "\n",
    "df=pd.concat([df,pd.DataFrame(data_dict)],ignore_index = True)\n",
    "df.to_csv(\"result.csv\", index=False)\n",
    "data_dict = {'MODEL':[],\n",
    "        'EPOCH':[],\n",
    "        'TRAINACC':[],\n",
    "        'TRAINLOSS':[],\n",
    "        'TESTACC':[],\n",
    "        'TESTLOSS':[],\n",
    "        'TIME':[],\n",
    "        'TRAINPRECISION':[],\n",
    "        'TRAINRECALL':[],\n",
    "        'TRAINF1SCORE':[],\n",
    "        'TESTPRECISION':[],\n",
    "        'TESTRECALL':[],\n",
    "        'TESTF1SCORE':[],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cc3f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af9d68e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d103e817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17564aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888f69f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727f6dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ccf33a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d713a662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63648144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed094c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6756bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b0b369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b9f639c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3989c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GaborNN5layer import GaborNN5layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c598287",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GaborNN5layer().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(net.parameters())\n",
    "#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.01, max_lr=0.1,cycle_momentum=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47cfb9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_layer_gnet_acc_train = []\n",
    "one_layer_gnet_acc_test = []\n",
    "time_per_image_train = []\n",
    "time_per_image_test = []\n",
    "epochs=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9710e86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] train_acc: 0.497 train_loss: 0.005\n",
      "[1] test_acc: 0.518 test_loss: 0.006\n",
      "Time Taken in Epoch 1  Seconds: 1143.6660904000018\n",
      "[2] train_acc: 0.523 train_loss: 0.005\n",
      "[2] test_acc: 0.553 test_loss: 0.005\n",
      "Time Taken in Epoch 2  Seconds: 1139.3039456000115\n",
      "[3] train_acc: 0.539 train_loss: 0.005\n",
      "[3] test_acc: 0.542 test_loss: 0.005\n",
      "Time Taken in Epoch 3  Seconds: 1151.366920200002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] train_acc: 0.537 train_loss: 0.005\n",
      "[4] test_acc: 0.546 test_loss: 0.005\n",
      "Time Taken in Epoch 4  Seconds: 1137.5177123999893\n",
      "[5] train_acc: 0.586 train_loss: 0.005\n",
      "[5] test_acc: 0.627 test_loss: 0.005\n",
      "Time Taken in Epoch 5  Seconds: 1137.7180198999995\n",
      "[6] train_acc: 0.624 train_loss: 0.005\n",
      "[6] test_acc: 0.684 test_loss: 0.005\n",
      "Time Taken in Epoch 6  Seconds: 1136.7451956999867\n",
      "[7] train_acc: 0.647 train_loss: 0.005\n",
      "[7] test_acc: 0.686 test_loss: 0.005\n",
      "Time Taken in Epoch 7  Seconds: 1138.260922699992\n",
      "[8] train_acc: 0.668 train_loss: 0.005\n",
      "[8] test_acc: 0.706 test_loss: 0.004\n",
      "Time Taken in Epoch 8  Seconds: 1135.7440130999894\n",
      "[9] train_acc: 0.674 train_loss: 0.005\n",
      "[9] test_acc: 0.690 test_loss: 0.005\n",
      "Time Taken in Epoch 9  Seconds: 1138.4697948000103\n",
      "[10] train_acc: 0.684 train_loss: 0.005\n",
      "[10] test_acc: 0.730 test_loss: 0.004\n",
      "Time Taken in Epoch 10  Seconds: 1144.1515679000004\n",
      "[11] train_acc: 0.688 train_loss: 0.004\n",
      "[11] test_acc: 0.726 test_loss: 0.004\n",
      "Time Taken in Epoch 11  Seconds: 1149.7403959000076\n",
      "[12] train_acc: 0.700 train_loss: 0.004\n",
      "[12] test_acc: 0.733 test_loss: 0.004\n",
      "Time Taken in Epoch 12  Seconds: 1132.255216999998\n",
      "[13] train_acc: 0.711 train_loss: 0.004\n",
      "[13] test_acc: 0.748 test_loss: 0.004\n",
      "Time Taken in Epoch 13  Seconds: 1144.4733627000096\n",
      "[14] train_acc: 0.718 train_loss: 0.004\n",
      "[14] test_acc: 0.745 test_loss: 0.004\n",
      "Time Taken in Epoch 14  Seconds: 1141.7380797000078\n",
      "[15] train_acc: 0.724 train_loss: 0.004\n",
      "[15] test_acc: 0.734 test_loss: 0.004\n",
      "Time Taken in Epoch 15  Seconds: 1137.0676942999999\n",
      "[16] train_acc: 0.728 train_loss: 0.004\n",
      "[16] test_acc: 0.752 test_loss: 0.004\n",
      "Time Taken in Epoch 16  Seconds: 1145.6859303999954\n",
      "[17] train_acc: 0.728 train_loss: 0.004\n",
      "[17] test_acc: 0.752 test_loss: 0.004\n",
      "Time Taken in Epoch 17  Seconds: 1136.7612798999908\n",
      "[18] train_acc: 0.738 train_loss: 0.004\n",
      "[18] test_acc: 0.752 test_loss: 0.004\n",
      "Time Taken in Epoch 18  Seconds: 1138.3585156000045\n",
      "[19] train_acc: 0.745 train_loss: 0.004\n",
      "[19] test_acc: 0.761 test_loss: 0.004\n",
      "Time Taken in Epoch 19  Seconds: 1130.2509690000006\n",
      "[20] train_acc: 0.747 train_loss: 0.004\n",
      "[20] test_acc: 0.766 test_loss: 0.004\n",
      "Time Taken in Epoch 20  Seconds: 1133.8702017000032\n",
      "[21] train_acc: 0.751 train_loss: 0.004\n",
      "[21] test_acc: 0.752 test_loss: 0.004\n",
      "Time Taken in Epoch 21  Seconds: 1139.3529085000046\n",
      "[22] train_acc: 0.756 train_loss: 0.004\n",
      "[22] test_acc: 0.770 test_loss: 0.004\n",
      "Time Taken in Epoch 22  Seconds: 1138.9191576000012\n",
      "[23] train_acc: 0.760 train_loss: 0.004\n",
      "[23] test_acc: 0.759 test_loss: 0.004\n",
      "Time Taken in Epoch 23  Seconds: 1133.706456999993\n",
      "[24] train_acc: 0.770 train_loss: 0.004\n",
      "[24] test_acc: 0.766 test_loss: 0.004\n",
      "Time Taken in Epoch 24  Seconds: 1133.6443931999966\n",
      "[25] train_acc: 0.771 train_loss: 0.004\n",
      "[25] test_acc: 0.766 test_loss: 0.004\n",
      "Time Taken in Epoch 25  Seconds: 1139.4749515999865\n",
      "[26] train_acc: 0.779 train_loss: 0.004\n",
      "[26] test_acc: 0.762 test_loss: 0.004\n",
      "Time Taken in Epoch 26  Seconds: 1138.4930254000064\n",
      "[27] train_acc: 0.783 train_loss: 0.003\n",
      "[27] test_acc: 0.757 test_loss: 0.004\n",
      "Time Taken in Epoch 27  Seconds: 1138.0184649000003\n",
      "[28] train_acc: 0.788 train_loss: 0.003\n",
      "[28] test_acc: 0.757 test_loss: 0.004\n",
      "Time Taken in Epoch 28  Seconds: 1136.532549799973\n",
      "[29] train_acc: 0.789 train_loss: 0.003\n",
      "[29] test_acc: 0.770 test_loss: 0.004\n",
      "Time Taken in Epoch 29  Seconds: 1147.7059021999885\n",
      "[30] train_acc: 0.797 train_loss: 0.003\n",
      "[30] test_acc: 0.760 test_loss: 0.004\n",
      "Time Taken in Epoch 30  Seconds: 1155.034463899996\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "trainingData(net,criterion,optimizer,epochs,'GaborNN5layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3acc0c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, \"GaborNN5layer.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a2f89447",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"result.csv\");\n",
    "\n",
    "df=pd.concat([df,pd.DataFrame(data_dict)],ignore_index = True)\n",
    "df.to_csv(\"result.csv\", index=False)\n",
    "data_dict = {'MODEL':[],\n",
    "        'EPOCH':[],\n",
    "        'TRAINACC':[],\n",
    "        'TRAINLOSS':[],\n",
    "        'TESTACC':[],\n",
    "        'TESTLOSS':[],\n",
    "        'TIME':[],\n",
    "        'TRAINPRECISION':[],\n",
    "        'TRAINRECALL':[],\n",
    "        'TRAINF1SCORE':[],\n",
    "        'TESTPRECISION':[],\n",
    "        'TESTRECALL':[],\n",
    "        'TESTF1SCORE':[],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "03a18e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaborNN5layer(\n",
       "  (g1): GaborConv2dLayer(\n",
       "    (conv_layer): Conv2d(3, 32, kernel_size=(15, 15), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (c1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (c2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (c3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (c4): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=25088, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('GaborNN5layer.pt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46a85a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788f86eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54792e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7614753e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GaborNNWithBN import GaborNNWithBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5490e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GaborNNWithBN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(net.parameters())\n",
    "#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.01, max_lr=0.1,cycle_momentum=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4cb719a",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_layer_gnet_acc_train = []\n",
    "one_layer_gnet_acc_test = []\n",
    "time_per_image_train = []\n",
    "time_per_image_test = []\n",
    "epochs=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "817dfdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] train_acc: 0.536 train_loss: 0.006\n",
      "[1] test_acc: 0.586 test_loss: 0.005\n",
      "Time Taken in Epoch 1  Seconds: 1183.140026499983\n",
      "[2] train_acc: 0.587 train_loss: 0.005\n",
      "[2] test_acc: 0.628 test_loss: 0.005\n",
      "Time Taken in Epoch 2  Seconds: 1160.1024382000032\n",
      "[3] train_acc: 0.611 train_loss: 0.005\n",
      "[3] test_acc: 0.651 test_loss: 0.005\n",
      "Time Taken in Epoch 3  Seconds: 1089.3362362000044\n",
      "[4] train_acc: 0.627 train_loss: 0.005\n",
      "[4] test_acc: 0.657 test_loss: 0.005\n",
      "Time Taken in Epoch 4  Seconds: 1091.065654200007\n",
      "[5] train_acc: 0.638 train_loss: 0.005\n",
      "[5] test_acc: 0.677 test_loss: 0.005\n",
      "Time Taken in Epoch 5  Seconds: 1124.5300399999833\n",
      "[6] train_acc: 0.653 train_loss: 0.005\n",
      "[6] test_acc: 0.678 test_loss: 0.005\n",
      "Time Taken in Epoch 6  Seconds: 1126.738545100001\n",
      "[7] train_acc: 0.662 train_loss: 0.005\n",
      "[7] test_acc: 0.697 test_loss: 0.005\n",
      "Time Taken in Epoch 7  Seconds: 1136.7381032999838\n",
      "[8] train_acc: 0.673 train_loss: 0.005\n",
      "[8] test_acc: 0.723 test_loss: 0.004\n",
      "Time Taken in Epoch 8  Seconds: 1165.9266418000043\n",
      "[9] train_acc: 0.685 train_loss: 0.005\n",
      "[9] test_acc: 0.717 test_loss: 0.004\n",
      "Time Taken in Epoch 9  Seconds: 1250.8769238000095\n",
      "[10] train_acc: 0.692 train_loss: 0.004\n",
      "[10] test_acc: 0.709 test_loss: 0.004\n",
      "Time Taken in Epoch 10  Seconds: 1077.8462207999837\n",
      "[11] train_acc: 0.708 train_loss: 0.004\n",
      "[11] test_acc: 0.730 test_loss: 0.004\n",
      "Time Taken in Epoch 11  Seconds: 1135.0028472999984\n",
      "[12] train_acc: 0.717 train_loss: 0.004\n",
      "[12] test_acc: 0.743 test_loss: 0.004\n",
      "Time Taken in Epoch 12  Seconds: 1116.324764400022\n",
      "[13] train_acc: 0.723 train_loss: 0.004\n",
      "[13] test_acc: 0.737 test_loss: 0.004\n",
      "Time Taken in Epoch 13  Seconds: 1206.5080672999902\n",
      "[14] train_acc: 0.726 train_loss: 0.004\n",
      "[14] test_acc: 0.738 test_loss: 0.004\n",
      "Time Taken in Epoch 14  Seconds: 1181.416938200011\n",
      "[15] train_acc: 0.741 train_loss: 0.004\n",
      "[15] test_acc: 0.743 test_loss: 0.004\n",
      "Time Taken in Epoch 15  Seconds: 1202.135135599994\n",
      "[16] train_acc: 0.744 train_loss: 0.004\n",
      "[16] test_acc: 0.741 test_loss: 0.004\n",
      "Time Taken in Epoch 16  Seconds: 1058.914379599999\n",
      "[17] train_acc: 0.750 train_loss: 0.004\n",
      "[17] test_acc: 0.756 test_loss: 0.004\n",
      "Time Taken in Epoch 17  Seconds: 1042.228248600004\n",
      "[18] train_acc: 0.757 train_loss: 0.004\n",
      "[18] test_acc: 0.759 test_loss: 0.004\n",
      "Time Taken in Epoch 18  Seconds: 1183.463298399991\n",
      "[19] train_acc: 0.764 train_loss: 0.004\n",
      "[19] test_acc: 0.768 test_loss: 0.004\n",
      "Time Taken in Epoch 19  Seconds: 1131.4248283999914\n",
      "[20] train_acc: 0.775 train_loss: 0.004\n",
      "[20] test_acc: 0.742 test_loss: 0.004\n",
      "Time Taken in Epoch 20  Seconds: 1178.2782665000123\n",
      "[21] train_acc: 0.779 train_loss: 0.004\n",
      "[21] test_acc: 0.748 test_loss: 0.004\n",
      "Time Taken in Epoch 21  Seconds: 1092.424129299994\n",
      "[22] train_acc: 0.783 train_loss: 0.003\n",
      "[22] test_acc: 0.756 test_loss: 0.004\n",
      "Time Taken in Epoch 22  Seconds: 1094.3031729000213\n",
      "[23] train_acc: 0.793 train_loss: 0.003\n",
      "[23] test_acc: 0.743 test_loss: 0.004\n",
      "Time Taken in Epoch 23  Seconds: 1092.1351824000012\n",
      "[24] train_acc: 0.800 train_loss: 0.003\n",
      "[24] test_acc: 0.759 test_loss: 0.005\n",
      "Time Taken in Epoch 24  Seconds: 1093.192779600009\n",
      "[25] train_acc: 0.806 train_loss: 0.003\n",
      "[25] test_acc: 0.757 test_loss: 0.005\n",
      "Time Taken in Epoch 25  Seconds: 1097.3578335999919\n",
      "[26] train_acc: 0.815 train_loss: 0.003\n",
      "[26] test_acc: 0.765 test_loss: 0.004\n",
      "Time Taken in Epoch 26  Seconds: 1126.8822464999976\n",
      "[27] train_acc: 0.825 train_loss: 0.003\n",
      "[27] test_acc: 0.778 test_loss: 0.005\n",
      "Time Taken in Epoch 27  Seconds: 1141.4378340000112\n",
      "[28] train_acc: 0.831 train_loss: 0.003\n",
      "[28] test_acc: 0.758 test_loss: 0.005\n",
      "Time Taken in Epoch 28  Seconds: 1115.2144061000145\n",
      "[29] train_acc: 0.838 train_loss: 0.003\n",
      "[29] test_acc: 0.750 test_loss: 0.005\n",
      "Time Taken in Epoch 29  Seconds: 1100.386416399997\n",
      "[30] train_acc: 0.842 train_loss: 0.003\n",
      "[30] test_acc: 0.740 test_loss: 0.005\n",
      "Time Taken in Epoch 30  Seconds: 1097.2241532999906\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "trainingData(net,criterion,optimizer,epochs,'GaborNNWithBN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "841ce263",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, \"GaborNNWithBN.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "249839c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"result.csv\");\n",
    "\n",
    "df=pd.concat([df,pd.DataFrame(data_dict)],ignore_index = True)\n",
    "df.to_csv(\"result.csv\", index=False)\n",
    "data_dict = {'MODEL':[],\n",
    "        'EPOCH':[],\n",
    "        'TRAINACC':[],\n",
    "        'TRAINLOSS':[],\n",
    "        'TESTACC':[],\n",
    "        'TESTLOSS':[],\n",
    "        'TIME':[],\n",
    "        'TRAINPRECISION':[],\n",
    "        'TRAINRECALL':[],\n",
    "        'TRAINF1SCORE':[],\n",
    "        'TESTPRECISION':[],\n",
    "        'TESTRECALL':[],\n",
    "        'TESTF1SCORE':[],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "becd52be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaborNNWithBN(\n",
       "  (g1): GaborConv2dLayer(\n",
       "    (conv_layer): Conv2d(3, 32, kernel_size=(15, 15), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (c1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (c2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (c3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (c4): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=25088, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('GaborNNWithBN.pt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fefc8744",
   "metadata": {},
   "outputs": [],
   "source": [
    "net =torch.load('GABORNN.pt')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(net.parameters())\n",
    "#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.01, max_lr=0.1,cycle_momentum=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "880676ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'MODEL':[],\n",
    "        'EPOCH':[],\n",
    "        'TRAINACC':[],\n",
    "        'TRAINLOSS':[],\n",
    "        'TESTACC':[],\n",
    "        'TESTLOSS':[],\n",
    "        'TIME':[],\n",
    "        'TRAINPRECISION':[],\n",
    "        'TRAINRECALL':[],\n",
    "        'TRAINF1SCORE':[],\n",
    "        'TESTPRECISION':[],\n",
    "        'TESTRECALL':[],\n",
    "        'TESTF1SCORE':[],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a969287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_layer_gnet_acc_train = []\n",
    "one_layer_gnet_acc_test = []\n",
    "time_per_image_train = []\n",
    "time_per_image_test = []\n",
    "epochs=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc62e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cfc86a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GaborPretrainedModel import GaborPretrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7f1c5f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "net =GaborPretrainedModel.VGGNET16().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eca8e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_layer_gnet_acc_train = []\n",
    "one_layer_gnet_acc_test = []\n",
    "time_per_image_train = []\n",
    "time_per_image_test = []\n",
    "epochs=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "95ef7f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] train_acc: 0.568 train_loss: 0.005\n",
      "[1] test_acc: 0.630 test_loss: 0.005\n",
      "Time Taken in Epoch 1  Seconds: 9854.303953500028\n",
      "[2] train_acc: 0.586 train_loss: 0.005\n",
      "[2] test_acc: 0.587 test_loss: 0.005\n",
      "Time Taken in Epoch 2  Seconds: 9863.037573199981\n",
      "[3] train_acc: 0.589 train_loss: 0.005\n",
      "[3] test_acc: 0.600 test_loss: 0.005\n",
      "Time Taken in Epoch 3  Seconds: 9854.544596799999\n",
      "[4] train_acc: 0.592 train_loss: 0.005\n",
      "[4] test_acc: 0.619 test_loss: 0.005\n",
      "Time Taken in Epoch 4  Seconds: 9775.889253100002\n",
      "[5] train_acc: 0.600 train_loss: 0.005\n",
      "[5] test_acc: 0.625 test_loss: 0.005\n",
      "Time Taken in Epoch 5  Seconds: 14488.72169939999\n",
      "[6] train_acc: 0.604 train_loss: 0.005\n",
      "[6] test_acc: 0.661 test_loss: 0.005\n",
      "Time Taken in Epoch 6  Seconds: 12614.209830000007\n",
      "[7] train_acc: 0.595 train_loss: 0.005\n",
      "[7] test_acc: 0.636 test_loss: 0.005\n",
      "Time Taken in Epoch 7  Seconds: 12731.281141499989\n",
      "[8] train_acc: 0.596 train_loss: 0.005\n",
      "[8] test_acc: 0.625 test_loss: 0.005\n",
      "Time Taken in Epoch 8  Seconds: 12491.81154830003\n",
      "[9] train_acc: 0.604 train_loss: 0.005\n",
      "[9] test_acc: 0.619 test_loss: 0.005\n",
      "Time Taken in Epoch 9  Seconds: 12231.98203459999\n",
      "[10] train_acc: 0.601 train_loss: 0.005\n",
      "[10] test_acc: 0.644 test_loss: 0.005\n",
      "Time Taken in Epoch 10  Seconds: 11853.530551600037\n",
      "[11] train_acc: 0.590 train_loss: 0.005\n",
      "[11] test_acc: 0.668 test_loss: 0.005\n",
      "Time Taken in Epoch 11  Seconds: 11520.02623269998\n",
      "[12] train_acc: 0.596 train_loss: 0.005\n",
      "[12] test_acc: 0.628 test_loss: 0.005\n",
      "Time Taken in Epoch 12  Seconds: 12444.166980799986\n",
      "[13] train_acc: 0.602 train_loss: 0.005\n",
      "[13] test_acc: 0.645 test_loss: 0.005\n",
      "Time Taken in Epoch 13  Seconds: 12373.06754629995\n",
      "[14] train_acc: 0.602 train_loss: 0.005\n",
      "[14] test_acc: 0.655 test_loss: 0.005\n",
      "Time Taken in Epoch 14  Seconds: 12696.793834700016\n",
      "[15] train_acc: 0.600 train_loss: 0.005\n",
      "[15] test_acc: 0.658 test_loss: 0.005\n",
      "Time Taken in Epoch 15  Seconds: 12339.056190900039\n",
      "[16] train_acc: 0.605 train_loss: 0.005\n",
      "[16] test_acc: 0.668 test_loss: 0.005\n",
      "Time Taken in Epoch 16  Seconds: 12073.411360100028\n",
      "[17] train_acc: 0.597 train_loss: 0.005\n",
      "[17] test_acc: 0.674 test_loss: 0.005\n",
      "Time Taken in Epoch 17  Seconds: 12056.1267506\n",
      "[18] train_acc: 0.610 train_loss: 0.005\n",
      "[18] test_acc: 0.656 test_loss: 0.005\n",
      "Time Taken in Epoch 18  Seconds: 11829.720535800036\n",
      "[19] train_acc: 0.609 train_loss: 0.005\n",
      "[19] test_acc: 0.678 test_loss: 0.005\n",
      "Time Taken in Epoch 19  Seconds: 12267.33296920004\n",
      "[20] train_acc: 0.598 train_loss: 0.005\n",
      "[20] test_acc: 0.612 test_loss: 0.005\n",
      "Time Taken in Epoch 20  Seconds: 12788.161189899954\n",
      "[21] train_acc: 0.605 train_loss: 0.005\n",
      "[21] test_acc: 0.655 test_loss: 0.005\n",
      "Time Taken in Epoch 21  Seconds: 12514.826599400025\n",
      "[22] train_acc: 0.605 train_loss: 0.005\n",
      "[22] test_acc: 0.655 test_loss: 0.005\n",
      "Time Taken in Epoch 22  Seconds: 12106.099423800013\n",
      "[23] train_acc: 0.604 train_loss: 0.005\n",
      "[23] test_acc: 0.629 test_loss: 0.005\n",
      "Time Taken in Epoch 23  Seconds: 12170.3171708\n",
      "[24] train_acc: 0.607 train_loss: 0.005\n",
      "[24] test_acc: 0.665 test_loss: 0.005\n",
      "Time Taken in Epoch 24  Seconds: 12031.880382500007\n",
      "[25] train_acc: 0.605 train_loss: 0.005\n",
      "[25] test_acc: 0.677 test_loss: 0.005\n",
      "Time Taken in Epoch 25  Seconds: 25613.698346999998\n",
      "[26] train_acc: 0.596 train_loss: 0.005\n",
      "[26] test_acc: 0.636 test_loss: 0.005\n",
      "Time Taken in Epoch 26  Seconds: 12418.321333299973\n",
      "[27] train_acc: 0.608 train_loss: 0.005\n",
      "[27] test_acc: 0.673 test_loss: 0.005\n",
      "Time Taken in Epoch 27  Seconds: 12275.060743899958\n",
      "[28] train_acc: 0.602 train_loss: 0.005\n",
      "[28] test_acc: 0.642 test_loss: 0.005\n",
      "Time Taken in Epoch 28  Seconds: 11642.872157600068\n",
      "[29] train_acc: 0.602 train_loss: 0.005\n",
      "[29] test_acc: 0.683 test_loss: 0.005\n",
      "Time Taken in Epoch 29  Seconds: 10619.626048199949\n",
      "[30] train_acc: 0.600 train_loss: 0.005\n",
      "[30] test_acc: 0.624 test_loss: 0.005\n",
      "Time Taken in Epoch 30  Seconds: 10243.235424299957\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "trainingData(net,criterion,optimizer,epochs,'VGGNET16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cfe12444",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, \"VGGNET16.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5c2a9ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"result.csv\");\n",
    "\n",
    "df=pd.concat([df,pd.DataFrame(data_dict)],ignore_index = True)\n",
    "df.to_csv(\"result.csv\", index=False)\n",
    "data_dict = {'MODEL':[],\n",
    "        'EPOCH':[],\n",
    "        'TRAINACC':[],\n",
    "        'TRAINLOSS':[],\n",
    "        'TESTACC':[],\n",
    "        'TESTLOSS':[],\n",
    "        'TIME':[],\n",
    "        'TRAINPRECISION':[],\n",
    "        'TRAINRECALL':[],\n",
    "        'TRAINF1SCORE':[],\n",
    "        'TESTPRECISION':[],\n",
    "        'TESTRECALL':[],\n",
    "        'TESTF1SCORE':[],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c548b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd61088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2f6744f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GaborNNWithResnet import GaborNNWithResnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2a7166c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net =GaborNNWithResnet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d3ad1742",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_layer_gnet_acc_train = []\n",
    "one_layer_gnet_acc_test = []\n",
    "time_per_image_train = []\n",
    "time_per_image_test = []\n",
    "epochs=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1db996f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] train_acc: 0.633 train_loss: 0.005\n",
      "[1] test_acc: 0.680 test_loss: 0.005\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'RESNET18\\\\RESNET181.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22760/1638859117.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainingData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'RESNET18'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22760/746026258.py\u001b[0m in \u001b[0;36mtrainingData\u001b[1;34m(net, criterion, optimizer, epochs, modelName)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mepochTime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mepochTime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0msetDataDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelName\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcorrect\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_loss\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochTime\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainPrecisionScore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainRecallScore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainF1score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtestPrecisionScore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtestRecallScore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtestF1score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodelName\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"\\\\\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mmodelName\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Time Taken in Epoch \"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"  Seconds: \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochTime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    374\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'RESNET18\\\\RESNET181.pt'"
     ]
    }
   ],
   "source": [
    "trainingData(net,criterion,optimizer,epochs,'RESNET18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32f329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, \"RESNET18.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10713493",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"result.csv\");\n",
    "\n",
    "df=pd.concat([df,pd.DataFrame(data_dict)],ignore_index = True)\n",
    "df.to_csv(\"result.csv\", index=False)\n",
    "data_dict = {'MODEL':[],\n",
    "        'EPOCH':[],\n",
    "        'TRAINACC':[],\n",
    "        'TRAINLOSS':[],\n",
    "        'TESTACC':[],\n",
    "        'TESTLOSS':[],\n",
    "        'TIME':[],\n",
    "        'TRAINPRECISION':[],\n",
    "        'TRAINRECALL':[],\n",
    "        'TRAINF1SCORE':[],\n",
    "        'TESTPRECISION':[],\n",
    "        'TESTRECALL':[],\n",
    "        'TESTF1SCORE':[],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e4086f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd67292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c334927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
